{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataset: stores the samples and corresponding labels.\\nDataloader: put a iterator around the dataset.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset: stores the samples and corresponding labels.\n",
    "Dataloader: put a iterator around the dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# pytorch offers domain specific libraries like torchvision, torchaudio, torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training dataset\n",
    "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
      "          0.0000, 0.1451, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
      "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4667, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
      "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
      "          0.3647, 0.4157, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
      "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
      "          0.6588, 0.5490, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
      "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
      "          0.5922, 0.5647, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
      "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
      "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
      "          0.6157, 0.6196, 0.0431, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
      "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
      "          0.6235, 0.6627, 0.1882, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
      "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
      "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
      "          0.6196, 0.6627, 0.4667, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
      "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
      "          0.5765, 0.6118, 0.6980, 0.0000],\n",
      "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
      "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
      "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
      "          0.5412, 0.5882, 0.6471, 0.1686],\n",
      "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
      "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
      "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
      "          0.6745, 0.6314, 0.7412, 0.2431],\n",
      "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
      "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
      "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
      "          0.6000, 0.6353, 0.7686, 0.2275],\n",
      "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
      "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
      "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
      "          0.7725, 0.7412, 0.7216, 0.1412],\n",
      "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
      "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
      "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
      "          0.9686, 0.8627, 0.8078, 0.1922],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
      "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
      "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
      "          0.6353, 0.6196, 0.5922, 0.0431],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32) \n",
    "test_dataloader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "print(f\"{len(train_dataloader.dataset)}\")\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(X[0])\n",
    "    print(y)\n",
    "    print(X.shape)\n",
    "    print(y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "3\n",
      "name Nand\n",
      "id 1530\n",
      "age 25\n",
      "-------\n",
      "name gpu\n",
      "model 4070\n",
      "release_date 2024\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# Understanding *args and *kwargs\n",
    "# *   > args: positional arguments [packed into a tuple]\n",
    "# **  > kwargs: keyword arguments [packed into a dictionary]\n",
    "\n",
    "# when *used in front of an iterable (like list or touple) > * unpacks the items. \n",
    "# when **used in front of a dictionary > ** unpacks the key, values. \n",
    "\n",
    "def add_nums(*args):\n",
    "    print(sum(args)) # sum fn take a iterator\n",
    "\n",
    "add_nums( 1,2,3,4 )\n",
    "add_nums( 1,2 )\n",
    "\n",
    "\n",
    "def get_info(**kwargs):\n",
    "    for k,v in kwargs.items():\n",
    "        print(k,v)\n",
    "    print(\"-------\")\n",
    "\n",
    "get_info(name=\"Nand\", id=1530, age=\"25\")\n",
    "get_info(name=\"gpu\", model=4070, release_date=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "# to define a nn in pytorch, we create a class that inherits from mm.Module.\n",
    "# We define the layers of the network in the __init__ fn.\n",
    "# We specify how the data will pass through the network in the forward fn.\n",
    "  \n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    # __init__ is a method who is the initializer of a class.\n",
    "    # It is called when we create an instance of that class.\n",
    "    # basically, it defines the setup of the Model class.\n",
    "\n",
    "    # super.__init__ calls the initilizer of the parent class (nn.Module) so it can set all the necessary internals for Model.\n",
    "    # without this, Model will not be able to use the built-in functionalities of nn.Module\n",
    "\n",
    "    # def __init__(self, *args, **kwargs):\n",
    "    #     super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "\n",
    "        # logits: Raw, Unnormalized scores produced by final layer of a nn.\n",
    "        # logits: word came from statistics, where it is refers to log-odds function. \n",
    "        # After that we apply (i.e. softmax) and convert logits into probabilities.\n",
    "        # IMPORTANT 1: many loss functions (like CrossEntropyLoss) expect logits instead of probs because computations are more numerically stable.\n",
    "        # IMPORTANT 2: logits allow flexibity in deciding how to normalize the outputs. (for binay> apply Sigmoid  | for multiclass> apply softmax)\n",
    "\n",
    "        #\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = Model().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# in training apply softmax: For calculating loss\n",
    "# in testing/inference: No need for Softmax, use Argmax. (faster)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for current_batch_id, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if current_batch_id%100000 == 0 or current_batch_id == len(dataloader)-1:\n",
    "            current = (current_batch_id+1)*len(X)\n",
    "            print(f\"Loss: {loss.item():0.4f} | {current=}/{size}\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: [Correct:{correct*100:0.3f}%] | [AvgLoss: {test_loss:>2f}]\")\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: \", epoch+1, \"\\t\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_500.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model().to(device)\n",
    "model2.load_state_dict(torch.load('model_500.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tensor(9, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = test_data[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model2(x)\n",
    "\n",
    "print(y, pred[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2, 101],\n",
      "        [  3,   4, 102]]) torch.int64 torch.Size([2, 3]) cpu\n",
      "[[  1   2 101]\n",
      " [  3   4 102]] int64 (2, 3)\n",
      "tensor([[  1,   2, 101],\n",
      "        [  3,   4, 102]]) torch.int64 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tensors: similar to numpy array or matrices\n",
    "# in pytorch, tensors are used to encode the input and output of a model, also params of the model.\n",
    "\n",
    "# attributes of tensor: shape, dtype, device,....\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data = [\n",
    "    [1,2, 101],\n",
    "    [3,4, 102]\n",
    "]\n",
    "x = torch.tensor(data)\n",
    "print(x, x.dtype, x.shape, x.device) # by default tensors are created on CPU\n",
    "\n",
    "n = np.array(data)\n",
    "print(n, n.dtype, n.shape)\n",
    "\n",
    "y = torch.from_numpy(n)\n",
    "print(y, y.dtype, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]]) torch.int64 torch.Size([2, 3]) torch.Size([2, 3])\n",
      "tensor([[0.0020, 0.7559, 0.5122],\n",
      "        [0.3179, 0.5293, 0.9502]], dtype=torch.float16) torch.float16 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# new tensor can retain the properties (shape, datatype) of the argument tensor, unless explicitly overriden.\n",
    "# shape is an alias for .size() and was added to match numpy\n",
    "z = torch.ones_like(x)\n",
    "print(z, z.dtype, z.shape, z.size())\n",
    "\n",
    "w = torch.rand_like(x, dtype=torch.float16)\n",
    "print(w, w.dtype, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2, 101],\n",
      "        [  3,   4, 102]])\n",
      "tensor([  1,   2, 101])\n",
      "tensor([1, 3])\n",
      "tensor([[  1,  69, 101],\n",
      "        [  3,  69, 102]])\n"
     ]
    }
   ],
   "source": [
    "# indexing and slicing\n",
    "print(x)\n",
    "print(x[0]) # row\n",
    "print(x[:,0]) # col\n",
    "\n",
    "x[:, 1] = 69\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,  69, 101],\n",
      "        [  3,  69, 102]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[  1,  69, 101],\n",
      "        [  3,  69, 102],\n",
      "        [  1,  69, 101],\n",
      "        [  3,  69, 102]])\n",
      "tensor([[  1,  69, 101,   1,  69, 101],\n",
      "        [  3,  69, 102,   3,  69, 102]])\n",
      "tensor([[[  1,  69, 101],\n",
      "         [  3,  69, 102]],\n",
      "\n",
      "        [[  1,  69, 101],\n",
      "         [  3,  69, 102]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[  1,   1],\n",
      "         [ 69,  69],\n",
      "         [101, 101]],\n",
      "\n",
      "        [[  3,   3],\n",
      "         [ 69,  69],\n",
      "         [102, 102]]]) torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# joining tensors\n",
    "\n",
    "# cat: concatenate the given sequence along an exisitng dimension.\n",
    "# stack: concatenate the givem sequence along a new dimension.\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "a = torch.cat([x, x], dim=0)\n",
    "print(a)\n",
    "b = torch.cat([x, x], dim=1)\n",
    "print(b)\n",
    "\n",
    "\n",
    "c = torch.stack([x, x])\n",
    "print(c, c.shape)\n",
    "d = torch.stack([x, x], dim=-1) # so many possible dims...\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14963, 15066],\n",
      "        [15066, 15174]])\n",
      "tensor([[14963, 15066],\n",
      "        [15066, 15174]])\n",
      "tensor([[  1,   4,   9],\n",
      "        [  0,   1,   4],\n",
      "        [100, 121, 144]])\n",
      "tensor([[  1,   4,   9],\n",
      "        [  0,   1,   4],\n",
      "        [100, 121, 144]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication: @\n",
    "# element wise multiplication: *\n",
    "y1 = x @ x.T\n",
    "y2 = x.matmul(x.T) # same thing\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "\n",
    "p = torch.tensor(\n",
    "    [[1,2,3],\n",
    "     [0,1,2],\n",
    "     [10,11,12]]\n",
    ")\n",
    "\n",
    "z1 = p * p\n",
    "z2 = p.mul(p)\n",
    "\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42) torch.int64 torch.Size([])\n",
      "42 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# single element tensor\n",
    "sum = p.sum()\n",
    "print(sum, sum.dtype, sum.shape)\n",
    "sum_value = sum.item()\n",
    "print(sum_value, type(sum_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  5, 15],\n",
      "        [ 7,  6, 16],\n",
      "        [ 8,  7, 17]])\n",
      "tensor([[11, 10, 20],\n",
      "        [12, 11, 21],\n",
      "        [13, 12, 22]])\n",
      "tensor([[11, 12, 13],\n",
      "        [10, 11, 12],\n",
      "        [20, 21, 22]])\n"
     ]
    }
   ],
   "source": [
    "# in-place operatrions\n",
    "# these are denoted by a suffix \"_\"\n",
    "# in-place operatives save some meory, but also can be problematic when computing derivatives becuase of immediate loss of history. \n",
    "\n",
    "print(p)\n",
    "p.add_(5)\n",
    "print(p)\n",
    "p.t_()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) torch.float32\n",
      "[1. 1. 1. 1. 1.] float32\n",
      "tensor([70., 70., 70., 70., 70.])\n",
      "[70. 70. 70. 70. 70.]\n"
     ]
    }
   ],
   "source": [
    "# bridge with numpy\n",
    "# tensor on the CPU and numpy arrays share their underlying memory locations.\n",
    "# that means, change in one with reflect the same in other.\n",
    "\n",
    "a_tensor = torch.ones(5)\n",
    "print(a_tensor, a_tensor.dtype)\n",
    "b_numpy = a_tensor.numpy()\n",
    "print(b_numpy, b_numpy.dtype)\n",
    "\n",
    "a_tensor.add_(69)\n",
    "print(a_tensor)\n",
    "print(b_numpy)\n",
    "\n",
    "# same thing with happen when converting a numpy to tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: stores the samples and their corresponding laebls\n",
    "# Dataloader: wraps an iterable around the dataset.\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # root: path where data is stored\n",
    "    train=True, # specifies the split (train or test)\n",
    "    download=True, # download if not available in root\n",
    "    transform=ToTensor() # features and label transformation\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "rows, cols = 3,3\n",
    "for i in range(1, rows*cols+1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# squeeze: return a tensor with all the specified dims of input but remove the size 1.\n",
    "# input shape of tensor: 1xAxBx1xCx2 > squeeze > AxBxCx2\n",
    "# when dim of squeeze is given then remaining unchanged: Ax1xB > squeeze(dim=0) > Ax1xB\n",
    "#                                                        Ax1xB > squeeze(dim=1) > AxB\n",
    "\n",
    "sample_img = train_data[10][0]\n",
    "print(sample_img.shape)\n",
    "t = sample_img.squeeze(dim=0)\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "# must implement: __init__, __len__, __getitem__\n",
    "\n",
    "# imagese are stored in img_dir\n",
    "# labels in annotations_file\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        super().__init__()\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Returns no of samples in dataset\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # loads and returns a single sample from dataset at the given index\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[index, 0])\n",
    "        img = read_image(img_path)\n",
    "        label = self.img_labels.iloc[index, 1]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"raw_data\", # root: path where data is stored\n",
    "    train=True, # specifies the split (train or test)\n",
    "    download=True, # download if not available in root\n",
    "    # transform=ToTensor() # features and label transformation\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"raw_data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    # transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = CustomDataset(\"train_labels.csv\", \"train_images/\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # shuffle: reshuffling at every epoch to reduce model overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate through the dataset.\n",
    "# each iteration returns a batch of train features and labels.\n",
    "\n",
    "sample_batch_images, sample_batch_labels = next(iter(train_dataloader))\n",
    "print(sample_batch_images.shape, sample_batch_labels.shape)\n",
    "sample_example_feat, label = sample_batch_images[12], sample_batch_labels[12]\n",
    "\n",
    "plt.title(label)\n",
    "plt.imshow(sample_example_feat.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n"
     ]
    }
   ],
   "source": [
    "# torch.nn provides namespace all the building blcks to build any nn.\n",
    "# nn.Module > its a module that consists of other modules(layers). This nested structure allows for building and managing complex architectures easily.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we initialize the nn layers in __init__\n",
    "# every nn.Module subclass implements the operation on input data in 'forward' method\n",
    "\n",
    "# nn.Sequential: ordered container of modules. Data is passed through all the modules in the same order as defined.\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # converts 28*28 matrix image into 784 single vector\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), # applies a linear trasnformation: [y=x*W_T + b]\n",
    "            nn.ReLU(), # aaplies relu (rectified linear unit) element wise \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# now create an instance of our newly created Model Class and move i to device and see its structure.\n",
    "model = Model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0498, -0.0433, -0.0167, -0.0227, -0.0359,  0.0827,  0.0792, -0.0226,\n",
      "         -0.0303,  0.0251],\n",
      "        [-0.0673, -0.0375, -0.0102,  0.0468, -0.0761,  0.0800,  0.0755, -0.0056,\n",
      "          0.0378,  0.0400],\n",
      "        [-0.0100, -0.0157, -0.0503,  0.0017, -0.0518,  0.0727,  0.0736, -0.0417,\n",
      "          0.0123,  0.0229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0954, 0.0960, 0.0986, 0.0980, 0.0967, 0.1089, 0.1085, 0.0980, 0.0972,\n",
      "         0.1028],\n",
      "        [0.0926, 0.0954, 0.0980, 0.1038, 0.0918, 0.1073, 0.1068, 0.0985, 0.1028,\n",
      "         0.1031],\n",
      "        [0.0988, 0.0982, 0.0949, 0.0999, 0.0947, 0.1073, 0.1074, 0.0957, 0.1010,\n",
      "         0.1021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# to use the model, we pass the input data, this executes the model's forward\n",
    "# DO NOT CALL model.forward() DIRECTLY.\n",
    "\n",
    "x = torch.rand(3, 28, 28, device=device)\n",
    "logits = model(x)\n",
    "print(logits)\n",
    "\n",
    "pred_probs = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probs)\n",
    "\n",
    "y_pred = torch.argmax(pred_probs) # Returns the indices of the maximum value of ALL elements in the input tensor.\n",
    "print(y_pred)\n",
    "\n",
    "# for a batch input data\n",
    "for each in pred_probs:\n",
    "    print(torch.argmax(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "####################################################################################################\n",
      "linear_relu_stack.0.weight\n",
      "torch.Size([512, 784])\n",
      "tensor([[ 0.0129, -0.0279, -0.0043,  ..., -0.0027,  0.0242, -0.0286],\n",
      "        [-0.0167, -0.0013,  0.0223,  ...,  0.0124, -0.0235, -0.0090]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n",
      "linear_relu_stack.0.bias\n",
      "torch.Size([512])\n",
      "tensor([-0.0268,  0.0225], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n",
      "linear_relu_stack.2.weight\n",
      "torch.Size([512, 512])\n",
      "tensor([[-0.0190, -0.0112,  0.0250,  ..., -0.0148,  0.0160, -0.0221],\n",
      "        [-0.0122,  0.0218,  0.0026,  ..., -0.0205, -0.0418,  0.0378]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n",
      "linear_relu_stack.2.bias\n",
      "torch.Size([512])\n",
      "tensor([-0.0349,  0.0383], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n",
      "linear_relu_stack.4.weight\n",
      "torch.Size([10, 512])\n",
      "tensor([[-0.0234, -0.0013, -0.0124,  ..., -0.0043,  0.0060, -0.0300],\n",
      "        [-0.0411,  0.0219, -0.0309,  ..., -0.0346, -0.0364,  0.0336]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n",
      "linear_relu_stack.4.bias\n",
      "torch.Size([10])\n",
      "tensor([ 0.0321, -0.0113], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model parameters() and named_parameters()\n",
    "# 1st will give (param)\n",
    "# 2nd will give (name, param)\n",
    "\n",
    "print(model)\n",
    "print(\"#\"*100)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     print(f\"{param.shape}\\n{param[:2]}\\n\", \"-\"*50)\n",
    "\n",
    "# print(\"#\"*100)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}\\n{param.shape}\\n{param[:2]}\\n\", \"-\"*50)\n",
    "\n",
    "# here we wil only see the weights and biases for only linear sub module\n",
    "# other dont have anything > no param."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation with \"torch.autograd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0064, 0.6173, 0.8928, 0.9064, 0.6494],\n",
      "        [0.8565, 0.8730, 0.3878, 0.9410, 0.8413]])\n",
      "tensor([[ 0.4959,  0.5225, -0.7898,  0.1953, -0.9847],\n",
      "        [ 1.7296, -0.2732,  0.8624,  1.2395, -0.9022]])\n"
     ]
    }
   ],
   "source": [
    "# torch.rand:  reutrns a tensor of random numbers from uniform distribution on interval [0,1)\n",
    "# torch.randn: returns a tensor of random numbers from a normal distribution [mean=0, variance=1]\n",
    "\n",
    "print(torch.rand(2,5))\n",
    "print(torch.randn(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
    "\n",
    "# when training a NN, most freq used algo is back-propagation, \n",
    "# in which we adjust the parameters according to the gradient of the loss function with respect to the given param.\n",
    "# \n",
    "# To compute these gradients, pytorch has built in differentiation engine called \"torch.autograd\"\n",
    "\n",
    "x = torch.rand(5)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "w = torch.randn(5,3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = x@w + b\n",
    "\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0876, 0.1298, 0.1785],\n",
      "        [0.0259, 0.0383, 0.0527],\n",
      "        [0.0204, 0.0302, 0.0415],\n",
      "        [0.0921, 0.1363, 0.1876],\n",
      "        [0.1025, 0.1519, 0.2089]])\n",
      "tensor([0.1103, 0.1634, 0.2248])\n"
     ]
    }
   ],
   "source": [
    "# Computing Gradients\n",
    "\n",
    "# to optimize weights of parameters, we need to compute the derivative of loss fn with respecte to these parameters.\n",
    "# we need del(loss)/del(w)  and   del(loss)/del(b) under some fixed values of x, y.\n",
    "\n",
    "\n",
    "# to compute those derivatives we call \n",
    "loss.backward() \n",
    "#and then retrieve the values from\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Disabling Gradient Tracking\n",
    "\n",
    "# by default, all the 'requires_grad=True' tensors trakk their computational history.\n",
    "# But when we do not need to do that, (i.e. model inferencing when it is already trained), \n",
    "# we use 1) torch.no_grad()\n",
    "#        2) param.detach()\n",
    "\n",
    "z = x@w + b\n",
    "print(z.requires_grad)\n",
    "with torch.no_grad():\n",
    "    z = x@w + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "z = x@w + b\n",
    "print(z.requires_grad)\n",
    "z = z.detach()\n",
    "print(z.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optmizing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# Common Loss Functions:\n",
    "# nn.MSELoss > Man Square Error > Regression Tasks\n",
    "# nn.NLLLoss > NEgative Log Likelyhood > Classification Tasks\n",
    "# nn.CrossEntropyLoss > Combination of [nn.LogsoftMax and nn.NLLLoss]\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "# Process of adjusting model params in each training step\n",
    "# SGD, Adam, RMSProp,....\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "# inside training loop, optimization happens in 3 steps:\n",
    "\n",
    "# reset the gradient of model params.\n",
    "# gradients by default add up. To prevent double counting, we expliciltely zero them at each iteration.\n",
    "optimizer.zero_grad()  \n",
    "\n",
    "# Backpropagate the prediction loss. \n",
    "# Pytorch deposits the gradients of the loss w.r.t each param.\n",
    "loss.backward()\n",
    "\n",
    "# once we have gradients, we call optimze.step() to adjust the params by the gradients collected in the backward pass.\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch models store the learned params in an internal state dictionay\n",
    "# called, 'state_dict'\n",
    "torch.save(model.state_dict(), \"/path/to/save/model.pth\")\n",
    "\n",
    "# To load a model\n",
    "# 1. Need the skeleton/architecture of the model\n",
    "# 2. Need currespnding weights of this architecture.\n",
    "\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load('model.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# setting weights_only=True is a good practice.\n",
    "# more on: https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models\n",
    "# To limit the functions executed during unpickling to only those necessary for loading weights.\n",
    "# i.e. model.pth might have 1) weights 2) optimzer 3) learning_rate 4)....\n",
    "# while saving if we use only state_dict() then these will not other tensors.\n",
    "\n",
    "# setting model.eval() before inferencing: Set the Dropout and batch normalization layers to evaluation mode.\n",
    "# Failing to do this will result in inconsistent inference results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1156259/3678374834.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  m3 = torch.load('model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving model skeleton/architecture as well.\n",
    "# instead of passing model.state_dict, pass model\n",
    "torch.save(model, 'model.pth')\n",
    "m3 = torch.load('model.pth')\n",
    "m3\n",
    "\n",
    "# This approach uses Python pickle module when serializing the model, \n",
    "# thus it relies on the actual class definition to be available when loading the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
